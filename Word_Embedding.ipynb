{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Embedding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "guOvQm-Ju-bo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b82123d-20af-4507-8295-4e90df62c631"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANJveY6vwosT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import multiprocessing\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "from gensim.parsing.preprocessing import stem_text\n",
        "import re\n",
        "import sys\n",
        "## Converts to binary code\n",
        "import pandas as pd\n",
        "import base64\n",
        "import numpy as np\n",
        "# import imageio\n",
        "import os\n",
        "import scipy\n",
        "import gensim\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models import KeyedVectors\n",
        "# Load vectors directly from the file\n",
        "from gensim.models import TfidfModel\n",
        "from gensim.corpora import Dictionary\n",
        "import pprint\n",
        "import pickle\n",
        "## Converts to binary code\n",
        "import pandas as pd\n",
        "import base64\n",
        "import numpy as np\n",
        "# import imageio\n",
        "import os\n",
        "import scipy\n",
        "import gensim\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "import gensim.corpora as corpora\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px1tTwE2vJGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "22406def-37d6-406d-ef10-9707fb95dbf4"
      },
      "source": [
        "final = np.load('/content/gdrive/My Drive/IR Assignment/uniq_words.npy',allow_pickle=True)\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/IR Assignment/GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOjrJzwzxCrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a4b1e8d6-ce52-4495-dd5f-443a33985d2e"
      },
      "source": [
        "# example word= 'sorry'\n",
        "similar = model.most_similar(positive=['sorry'],topn=10)\n",
        "print(similar)\n",
        "print(similar[0][0].lower())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('deeply_sorry', 0.6862671375274658), ('ashamed', 0.6773370504379272), ('apologize', 0.6739750504493713), ('Sorry', 0.6318448185920715), ('sad', 0.6194046139717102), ('regretful', 0.6120024919509888), ('glad', 0.6091006994247437), ('embarassed', 0.6043713092803955), ('apologizing', 0.6028956174850464), ('embarrassed', 0.5970751047134399)]\n",
            "deeply_sorry\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}